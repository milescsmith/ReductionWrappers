% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dca.R
\name{dca}
\alias{dca}
\title{Deep count autoencoder}
\usage{
dca(exprDat, mode = "denoise", ae_type = "zinb-conddisp",
  normalize_per_cell = TRUE, scale = TRUE, log1p = TRUE,
  batchnorm = TRUE, activation = "relu", init = "glorot_uniform",
  epochs = 300, reduce_lr = 10, early_stop = 15, batch_size = 32,
  optimizer = "rmsprop", random_state = 0, threads = NULL,
  verbose = TRUE, return_model = FALSE, return_info = FALSE,
  copy = FALSE)
}
\arguments{
\item{exprDat}{Unnomalized, unscaled gene expression matrix, with cell names
as rows and gene names as columns}

\item{mode}{character. "denoise"(default), or "latent".  "denoise"
overwrites "adata.X" with denoised expression values.  In "latent" mode DCA
adds "adata.obsm["X_dca"]" to given adata object. This matrix represent
latent representation of cells via DCA.}

\item{ae_type}{character. "zinb-conddisp"(default), "zinb",
"nb-conddisp" or "nb".  Type of the autoencoder. Return values and the
architecture is determined by the type e.g. "nb" does not provide dropout
probabilities.}

\item{normalize_per_cell}{boolean (default: TRUE).  If true,
library size normalization is performed using the
"sc.pp.normalize_per_cell" function in Scanpy and saved into adata object.
Mean layer is re-introduces library size differences by scaling the mean
value of each cell in the output layer. See the manuscript for more
details.}

\item{scale}{boolean (default: TRUE).  If true, the input of the
autoencoder is centered using "sc.pp.scale" function of Scanpy. Note that
the output is kept as raw counts as loss functions are designed for the
count data.}

\item{log1p}{boolean (default: TRUE).  If true, the input of the
autoencoder is log transformed with a pseudocount of one using
"sc.pp.log1p" function of Scanpy.}

\item{batchnorm}{boolean (default: TRUE).  If true, batch
normalization is performed.}

\item{activation}{str (default: "relu").  Activation function of
hidden layers.}

\item{init}{str (default: "glorot_uniform").  Initialization
method used to initialize weights.}

\item{epochs}{integer (default: 300).  Number of total epochs in
training.}

\item{reduce_lr}{integer (default: 10).  Reduces learning rate if
validation loss does not improve in given number of epochs.}

\item{early_stop}{integer (default: 15).  Stops training if
validation loss does not improve in given number of epochs.}

\item{batch_size}{integer (default: 32).  Number of samples in the
batch used for SGD.}

\item{optimizer}{str (default: "rmsprop").  Type of optimization
method used for training.}

\item{random_state}{integer (default: 0).  Seed for python, numpy
and tensorflow.}

\item{threads}{integer or NULL (default: NULL).  Number of threads
to use in training. All cores are used by default.}

\item{verbose}{boolean (default: FALSE).  If true, prints
additional information about training and architecture.}

\item{return_model}{boolean (default: FALSE).  If true, trained
autoencoder object is returned. See "Returns".}

\item{return_info}{boolean (default: FALSE).  If true, all
additional parameters of DCA are stored in "adata.obsm" such as dropout
probabilities (obsm["X_dca_dropout"]) and estimated dispersion values
(obsm["X_dca_dispersion"]), in case that autoencoder is of type zinb or
zinb-conddisp.}

\item{copy}{boolean (default: FALSE). If true, a copy of anndata
is returned.}
}
\description{
Performs denoising of gene expression using dca
(https://github.com/theislab/dca)
Some arguments have been removed due to being troublesome in the R-Python
interface
}
